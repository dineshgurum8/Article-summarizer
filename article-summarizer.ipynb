{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Mining and Applied NLP (44-620)\n",
    "\n",
    "## Final Project: Article Summarizer\n",
    "\n",
    "### Student Name: Dinesh Gurumoorthy\n",
    "### Github link: https://github.com/dineshgurum8/Article-summarizer \n",
    "\n",
    "Perform the tasks described in the Markdown cells below.  When you have completed the assignment make sure your code cells have all been run (and have output beneath them) and ensure you have committed and pushed ALL of your changes to your assignment repository.\n",
    "\n",
    "You should bring in code from previous assignments to help you answer the questions below.\n",
    "\n",
    "Every question that requires you to write code will have a code cell underneath it; you may either write your entire solution in that cell or write it in a python file (`.py`), then import and run the appropriate code to answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "annotated-types         0.7.0\n",
      "asttokens               3.0.0\n",
      "beautifulsoup4          4.13.4\n",
      "blis                    1.3.0\n",
      "catalogue               2.0.10\n",
      "certifi                 2025.8.3\n",
      "charset-normalizer      3.4.2\n",
      "click                   8.2.1\n",
      "cloudpathlib            0.21.1\n",
      "colorama                0.4.6\n",
      "comm                    0.2.3\n",
      "confection              0.1.5\n",
      "contourpy               1.3.3\n",
      "cycler                  0.12.1\n",
      "cymem                   2.0.11\n",
      "debugpy                 1.8.15\n",
      "decorator               5.2.1\n",
      "en_core_web_sm          3.8.0\n",
      "executing               2.2.0\n",
      "fonttools               4.59.0\n",
      "html5lib                1.1\n",
      "idna                    3.10\n",
      "ipykernel               6.30.0\n",
      "ipython                 9.4.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.6\n",
      "joblib                  1.5.1\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.8.1\n",
      "kiwisolver              1.4.8\n",
      "langcodes               3.5.0\n",
      "language_data           1.3.0\n",
      "marisa-trie             1.2.1\n",
      "markdown-it-py          3.0.0\n",
      "MarkupSafe              3.0.2\n",
      "matplotlib              3.10.5\n",
      "matplotlib-inline       0.1.7\n",
      "mdurl                   0.1.2\n",
      "murmurhash              1.0.13\n",
      "nest-asyncio            1.6.0\n",
      "nltk                    3.9.1\n",
      "numpy                   2.3.2\n",
      "packaging               25.0\n",
      "parso                   0.8.4\n",
      "pillow                  11.3.0\n",
      "pip                     24.0\n",
      "platformdirs            4.3.8\n",
      "preshed                 3.0.10\n",
      "prompt_toolkit          3.0.51\n",
      "psutil                  7.0.0\n",
      "pure_eval               0.2.3\n",
      "pydantic                2.11.7\n",
      "pydantic_core           2.33.2\n",
      "Pygments                2.19.2\n",
      "pyparsing               3.2.3\n",
      "python-dateutil         2.9.0.post0\n",
      "pywin32                 311\n",
      "pyzmq                   27.0.1\n",
      "regex                   2025.7.34\n",
      "requests                2.32.4\n",
      "rich                    14.1.0\n",
      "setuptools              65.5.0\n",
      "shellingham             1.5.4\n",
      "six                     1.17.0\n",
      "smart_open              7.3.0.post1\n",
      "soupsieve               2.7\n",
      "spacy                   3.8.7\n",
      "spacy-legacy            3.0.12\n",
      "spacy-loggers           1.0.5\n",
      "spacytextblob           5.0.0\n",
      "srsly                   2.5.1\n",
      "stack-data              0.6.3\n",
      "textblob                0.19.0\n",
      "thinc                   8.3.6\n",
      "tornado                 6.5.1\n",
      "tqdm                    4.67.1\n",
      "traitlets               5.14.3\n",
      "typer                   0.16.0\n",
      "typing_extensions       4.14.1\n",
      "typing-inspection       0.4.1\n",
      "urllib3                 2.5.0\n",
      "wasabi                  1.1.3\n",
      "wcwidth                 0.2.13\n",
      "weasel                  0.4.1\n",
      "webencodings            0.5.1\n",
      "wrapt                   1.17.2\n",
      "All prereqs installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "import pathlib  \n",
    "import pickle  \n",
    "from collections import Counter\n",
    "import numpy as np  \n",
    "\n",
    "import requests  \n",
    "from bs4 import BeautifulSoup  \n",
    "import matplotlib.pyplot as plt  \n",
    "import spacy  \n",
    "from spacy.tokens import Doc  \n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "!pip list\n",
    "\n",
    "print(\"All prereqs installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find on the internet an article or blog post about a topic that interests you and you are able to get the text for using the technologies we have applied in the course.  Get the html for the article and store it in a file (which you must submit with your project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "\n",
      "1\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "“While AI can be a powerful tool for aiding and augmenting the writing process, it is not a direct replacement for the unique qualities that human writers bring to the table.”\n",
      "\n",
      "- OpenAi’s Artificial intelligence chatbot, ChatGPT\n",
      "\n",
      "During my first semester of college, a close friend of mine asked me if I felt threatened by the growing popularity of AI writing since I am a writing major. My immediate response was “no.” I responded this way for two reasons. First, I was too pri\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "\n",
    "url = \"https://aidenblakemagee.medium.com/ais-impact-on-human-writing-resource-or-replacement-060d261b012f\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    article_tag = soup.find('article')\n",
    "    if article_tag:\n",
    "        # Collect all paragraph texts inside the article tag\n",
    "        paragraphs = article_tag.find_all('p')\n",
    "        article_text = \"\\n\\n\".join(p.get_text() for p in paragraphs)\n",
    "        \n",
    "        print(article_text[:500])  # Print first 500 characters\n",
    "        \n",
    "        # Save to pickle\n",
    "        with open('article.pkl', 'wb') as f:\n",
    "            pickle.dump(article_text, f)\n",
    "    else:\n",
    "        print(\"No <article> tag found on the page.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read in your article's html source from the file you created in question 1 and do sentiment analysis on the article/post's text (use `.get_text()`).  Print the polarity score with an appropriate label.  Additionally print the number of sentences in the original article (with an appropriate label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "\n",
      "1\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "“While AI can be a powerful tool for aiding and augmenting the writing process, it is not a direct replacement for the unique qualities that human writers bring to the table.”\n",
      "\n",
      "- OpenAi’s Artificial intelligence chatbot, ChatGPT\n",
      "\n",
      "During my first semester of college, a close friend of mine asked me if I felt threatened by the growing popularity of AI writing since I am a writing major. My immediate response was “no.” I responded this way for two reasons. First, I was too prideful to even consider that AI could replace humans in the field of writing. Second, I did not know what AI was capable of. Now, as AI writing programs such as Jasper, Copy.ai, Chat GPT, and Sudowrite have grown in popularity, I do feel threatened and worried about the increasing usage of AI writing and its potential impact on human writers.\n",
      "\n",
      "Valued at $196 billion in 2023 and estimated to be worth over $1.8 trillion by 2030, the artificial intelligence industry is growing at a rapid pace. 77% of businesses have already adopted artificial intelligence or have an adoption plan, and by 2024, it is estimated that over 50% of large enterprises will utilize artificial intelligence in some shape or form. A study by McKinsey Global Institute predicts that as AI continues to evolve, 400 million workers could lose their jobs worldwide. It is also estimated that over 80% of U.S. workers will lose at least 10% of their daily tasks to AI. Americans are aware of this potential threat to the job industry. A survey conducted by Forbes Advisor determined that 77% of respondents are concerned that AI will cause job loss within the next 12 months.\n",
      "\n",
      "Artificial intelligence has and will continue to impact the industries of healthcare, customer service, finance, retail, cybersecurity, marketing, technology, and e-commerce. Writing is a field deeply connected to all of these industries — a connection far from unknown to the public. As I write this, a simple search on Google for “News on AI” results in hundreds of articles such as “AI’s Threat to Writing,” “The Risk of Losing Unique Voices: What Is The Impact Of AI On Writing?” and “The Only Way to Deal With the Threat From AI? Shut It Down.” AI’s impact on writing has caused many to believe that human writers might someday be replaced by AI writing, or at the very least, devalued by AI writing; this idea is believed for good reason.\n",
      "\n",
      "AI writing is extremely efficient. It might take a human 30 minutes to write 500 words of quality content, but an AI writing generator can write 500 words of quality content in a matter of seconds. This speed of production provides potential for AI to create drafts for writers to edit and revise until perfection. Second, AI can assist writers in both their creativity and innovation. AI has access to more information than a human mind could ever hold, allowing for plenty of content and substance for the writer to draw inspiration from. Third, AI can assist writers in research. AI’s access to information can help with creativity and innovation, but it can also provide research from its seemingly limitless resources.\n",
      "\n",
      "Despite these significant features, I believe that human writers should not be devalued or replaced due to AI’s capabilities. Here is why:\n",
      "\n",
      "Even though AI can help boost creativity and inspiration for writers, it can also destroy it. The concepts and ideas that AI generates might be new to the writer, but nothing it produces will be a new or original thought. All the information that AI produces is from something that already exists. The intelligence that AI holds is artificial — a product of human beings. AI tools cannot create anything outside of what they have been programmed to do. Furthermore, because AI can produce incredible work incredibly fast, writers can fall into both dependency and discouragement regarding their own creative work. The day that creativity dies will be the day that creators believe they cannot create any more.\n",
      "\n",
      "Additionally, lacking in original thought means that AI will inevitably exhibit bias. Bias is not only often unethical, but it can also hinder persuasive ability. For instance, if marketers want to successfully cater to an audience, they need to adopt certain biases. Using AI, a specific bias cannot be chosen since AI is pulling from thousands of sources that carry predetermined biases, which can ultimately make AI’s persuasive tactics weak, ineffective, and ethically insensitive. Plagiarism, attributed authorship, and data privacy are other important ideas to consider when evaluating the ethicality of AI writing. When using AI to publish work, individuals must ask themselves questions such as “Is the content I am releasing reliable and trustworthy?” or “Who should I credit for this writing?” or even “Has this data been stolen by someone who owns the rights to it?”\n",
      "\n",
      "AI’s accuracy cannot be trusted. AI is unable to accurately determine what is true based on its own judgment because it lacks the evaluative ability that humans possess. AI can only generate what humans think to be true, and we know that while one individual might hold an opinion or belief on a subject, another individual might believe a completely different view to be true on that same particular subject. We also know that what humans believe to be true can change over time as we continue to learn, so relying on AI to consistently provide accurate information should be approached cautiously. Ju Yoen Lee, a professor at Hanyang University School of Law, asserts that “AI chatbots can be competent but dangerous research assistants, and the authenticity of any AI-generated text must be verified. Researchers should always remember that although using AI chatbots is exciting and full of potential, it also comes with heavy responsibilities.”\n",
      "\n",
      "AI writing lacks emotional intelligence. “EI” is the ability to understand and manage your emotions, as well as recognize and influence the emotions of those around you. AI lacks in EI because AI cannot practice or experience emotions, and since AI cannot experience the emotions that humans do, it often cannot create writing that evokes emotion from its human readers. Because of this, feelings such as joy, sadness, and pain and tools such as sarcasm, persuasion, and personal anecdotes cannot be effectively conveyed by AI to its readers.\n",
      "\n",
      "AI’s imperfections should be important to three groups of people: the writers, the employers of writers, and everybody else. For the writers, they should be encouraged to continue writing. The glaring flaws of artificial intelligence should embolden writers to find value in their craft — whether they are a college sophomore like me, or a writer with thirty years of experience under their belt. The second group — the employers of writers — should recognize the necessity of having human writers. Human writers are able to evoke emotion, market, persuade, and captivate in ways that AI cannot. Last but certainly not least, the third group: everybody else. There’s a good chance that you fall into this category. Learn the extent of AI’s capabilities and recognize that it falls short in more ways than most people realize.\n",
      "\n",
      "While AI might pose significant threats to much of the job industry, traits such as originality, reliability, and emotional intelligence are highly valued in nearly every profession — all characteristics that AI so often fails to generate. If these three groups of people fail to see AI’s flaws, the value of human writers will certainly be lowered.\n",
      "\n",
      "AI provides many benefits — efficiency, inspiration, and research — for the industry of writing. However, its benefits should not be great enough to devalue or replace human writers. Lacking in original thought, emotional intelligence, and consistent reliability, artificial intelligence has too many weaknesses to overrule the priceless attributes human writers can provide. Perhaps as AI continues to advance, these issues will be improved and eventually eliminated, but for now, AI writing should be used as a resource, not a replacement.\n",
      "\n",
      "“Artificial Intelligence Market Size, Share, Growth Report 2030.” Artificial Intelligence Market Size, Share, Growth Report 2030, www.grandviewresearch.com/industry-analysis/artificial-intelligence-ai-market. Accessed 12 Oct. 2023.\n",
      "\n",
      "Bughin, Jacques, et al. “Skill Shift: Automation and the Future of the Workforce.” McKinsey & Company, McKinsey & Company, 23 May 2018, www.mckinsey.com/featured-insights/future-of-work/skill-shift-automation-and-the-future-of-the-workforce.\n",
      "\n",
      "“Emotional Intelligence in Leadership: Why It’s Important.” Business Insights Blog, 3 Apr. 2019, online.hbs.edu/blog/post/emotional-intelligence-in-leadership.\n",
      "\n",
      "Haan, Kathy. “Over 75% of Consumers Are Concerned about Misinformation from Artificial Intelligence.” Forbes, Forbes Magazine, 20 July 2023, www.forbes.com/advisor/business/artificial-intelligence-consumer-sentiment/.\n",
      "\n",
      "IBM Global AI Adoption Index 2022, www.ibm.com/downloads/cas/GVAGA3JP. Accessed 13 Oct. 2023.\n",
      "\n",
      "Lee, Ju Yoen. “Can an Artificial Intelligence Chatbot Be the Author of a Scholarly Article?” Science Editing, Korean Council of Science Editors, 16 Feb. 2023, doi.org/10.6087/kcse.292.\n"
     ]
    }
   ],
   "source": [
    "# Load the article from the .pkl file\n",
    "with open('article.pkl', 'rb') as f:\n",
    "    article_html = pickle.load(f)\n",
    "\n",
    "soup = BeautifulSoup(article_html, parser)\n",
    "article_text = soup.get_text(separator='\\n')\n",
    "\n",
    "# Print the text\n",
    "print(article_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent tokens (converted to lower case).  Print the common tokens with an appropriate label.  Additionally, print the tokens their frequencies (with appropriate labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ai', 58), ('writing', 21), ('writers', 19), ('intelligence', 16), ('human', 13)]\n"
     ]
    }
   ],
   "source": [
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "def we_care_about(token):\n",
    "    return not (token.is_space or token.is_punct or token.is_stop)\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "doc = nlp(article_text)\n",
    "\n",
    "# Getting rid of tokens we don't care about & converting to lowercase\n",
    "interesting_tokens = [token.text.lower() for token in doc if we_care_about(token)]\n",
    "\n",
    "# Determine the 5 most frequent tokens\n",
    "token_freq = Counter(map(str, interesting_tokens))\n",
    "print(token_freq.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Load the article text into a trained `spaCy` pipeline, and determine the 5 most frequent lemmas (converted to lower case).  Print the common lemmas with an appropriate label.  Additionally, print the lemmas with their frequencies (with appropriate labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ai', 58), ('writer', 22), ('writing', 18), ('human', 18), ('intelligence', 16)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "interesting_lemmas = [token.lemma_.lower() for token in doc if we_care_about(token)]\n",
    "\n",
    "# Determine the 5 most frequent lemmas\n",
    "lemma_freq = Counter(map(str, interesting_lemmas))\n",
    "print(lemma_freq.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Make a list containing the scores (using tokens) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores. From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Make a list containing the scores (using lemmas) of every sentence in the article, and plot a histogram with appropriate titles and axis labels of the scores.  From your histogram, what seems to be the most common range of scores (put the answer in a comment after your code)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Using the histograms from questions 5 and 6, decide a \"cutoff\" score for tokens and lemmas such that fewer than half the sentences would have a score greater than the cutoff score.  Record the scores in this Markdown cell\n",
    "\n",
    "* Cutoff Score (tokens): \n",
    "* Cutoff Score (lemmas):\n",
    "\n",
    "Feel free to change these scores as you generate your summaries.  Ideally, we're shooting for at least 6 sentences for our summary, but don't want more than 10 (these numbers are rough estimates; they depend on the length of your article)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Create a summary of the article by going through every sentence in the article and adding it to an (initially) empty list if its score (based on tokens) is greater than the cutoff score you identified in question 8.  If your loop variable is named `sent`, you may find it easier to add `sent.text.strip()` to your list of sentences.  Print the summary (I would cleanly generate the summary text by `join`ing the strings in your list together with a space (`' '.join(sentence_list)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Print the polarity score of your summary you generated with the token scores (with an appropriate label). Additionally, print the number of sentences in the summarized article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create a summary of the article by going through every sentence in the article and adding it to an (initially) empty list if its score (based on lemmas) is greater than the cutoff score you identified in question 8.  If your loop variable is named `sent`, you may find it easier to add `sent.text.strip()` to your list of sentences.  Print the summary (I would cleanly generate the summary text by `join`ing the strings in your list together with a space (`' '.join(sentence_list)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Print the polarity score of your summary you generated with the lemma scores (with an appropriate label). Additionally, print the number of sentences in the summarized article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.  Compare your polarity scores of your summaries to the polarity scores of the initial article.  Is there a difference?  Why do you think that may or may not be?.  Answer in this Markdown cell.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Based on your reading of the original article, which summary do you think is better (if there's a difference).  Why do you think this might be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
